{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fashion MNIST Neural Net example using PyTorch"
      ],
      "metadata": {
        "id": "xrWKQS0dV-cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2kxMvkjIWLhl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWkVwb9IWWUB",
        "outputId": "1466a95a-2b0e-4e27-c9ea-9b11848972ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 9.72MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 177kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 2.90MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 11.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "H75a8UJJYHF6",
        "outputId": "4a859f4e-0753-43a0-d513-8cfe5ce0fa13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 204);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for x,y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", x.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AayMzEa5W2xX",
        "outputId": "5fd7414a-ecd0-4d33-c69c-54cb59c56eef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68O0RbNNXbPs",
        "outputId": "0a99f625-2b17-4e03-dc32-db71655a878e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the NN model\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Hidden Layers with ReLU Activation Functions\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HimrkKOnYhIs",
        "outputId": "d2600656-94c3-48aa-b12c-c1bd3606fb52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy Loss Calculation\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Using SGD Optimizer\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "78DOIxMRZ5Oa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "      x, y =  x.to(device), y.to(device) # related to gpu computation\n",
        "\n",
        "      # Compute prediction error\n",
        "      pred = model(x)\n",
        "      loss = loss_fn(pred, y)\n",
        "\n",
        "      # Backpropagation\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        loss, current = loss.item(), batch * len(x)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      pred = model(x)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches # average loss per batch\n",
        "  correct /= size  # percentage of correct predictions or accuracy value\n",
        "\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "9drs7-qBaiRs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz4pKyjuccsv",
        "outputId": "91a5f31f-eb42-4174-9bab-518160797b22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.630552  [    0/60000]\n",
            "loss: 0.744291  [ 6400/60000]\n",
            "loss: 0.516423  [12800/60000]\n",
            "loss: 0.749706  [19200/60000]\n",
            "loss: 0.673996  [25600/60000]\n",
            "loss: 0.643479  [32000/60000]\n",
            "loss: 0.718101  [38400/60000]\n",
            "loss: 0.722028  [44800/60000]\n",
            "loss: 0.687846  [51200/60000]\n",
            "loss: 0.672468  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 76.4%, Avg loss: 0.670415 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_r17wlKcnrZ",
        "outputId": "5db09da0-eab9-4977-9137-fe3cd02bb170"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "\n",
        "x, y = test_data[9][0], test_data[9][1]\n",
        "x = x.to(device)\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "\n",
        "    print(f\"Predicted: {predicted}, Actual: {actual}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUB1mtSkdaie",
        "outputId": "f95cbff9-3979-4f84-f64e-051286d3efc4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: Sneaker, Actual: Sneaker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "f39eaac2",
        "outputId": "410681ba-207c-4ca5-b313-91b4d3f53347"
      },
      "source": [
        "plt.imshow(x.squeeze().cpu(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ihy_BpTefMxz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}